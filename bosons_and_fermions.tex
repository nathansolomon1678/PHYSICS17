\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{tikz-cd}

\begin{document}

\title{Bosons \& Fermions}
\author{Nathan Solomon}
\maketitle

\section{Maxwell-Boltzmann distribution}
The Boltzmann factor $e^{-\beta E}$ that we've been using up till now is only an approximation for the actual energy distibutions of particles. The actual distribution function comes in two forms -- one for bosons and another for fermions. Bosons are particles with integers spin, and they follow Bose-Einstein statistics. Fermions are particles with half-odd-integer spin, and they follow Fermi-Dirac distributions.

These differ from the Maxwell-Boltzmann energy distribution because for both bosons and fermions, particles with the same energy are indistinguishable (although if the degeneracy is greater than one there may be other factors distinguishing the particles). This means that we need to count ``macrostates" instead of ``microstates" in order to calculate the discrete distribution functions. But for now, we just care about the continuous distribution functions.

Fermi-Dirac and Bose-Einstein statistics differ from each other because fermions have the additional restriction that each energy level (or sublevel, if degeneracy is greater than one) can only have one particle.

\section{Bose-Einstein distribution}
In Maxwell-Boltzmann statistics, particles are distinguishable, meaning all microstates are equally likely, but in Bose-Einstein statistics, particles are indistinguishable, so all macrostates are equally likely. So to understand the energy distribution of a bunch of bosons, instead of looking at the energy levels for individual particles, look at the occupancy of individual energy levels. For an energy level $E$, the energy is $nE$, where $n$ is the number of particles for the energy level, so the Boltzmann factor (assuming $E$ is fixed and $n$ is variable) is
\[e^{- \beta E n}\]
So the average occupancy of an energy level with energy $E$ is
\[\overline{n}(E) = \frac{\sum\limits_{N=0}^\infty N e^{- \beta E N}}{\sum\limits_{N=0}^\infty e^{- \beta E N}}\]
Now you can use the following Taylor series for a nifty trick:
\[\sum_{n=0}^\infty x^n = \frac{1}{1 - x} \]
Differentiate that and multiply by $x$ to get another identity:
\[\sum_{n=0}^\infty nx^n = \frac{x}{(1-x)^2} \]
Now let $x$ be $e^{-\beta E}$ and apply those two identities to the denominator and the numerator of the formula for $\overline{n}(E)$ to get
\[\overline{n}(E) = \frac{ \frac{x}{(1-x)^2} }{ \frac{1}{1-x} } = \frac{x}{1 - x} = \frac{e^{-\beta E}}{1 - e^{-\beta E}} = \frac{1}{e^{\beta E} - 1} \]
This derivation is not quite correct though -- we still need to multiply by the degeneracy, $g$, to account for multiple independent states with the same energy. Also, the derivation above used $e^{-\beta E}$ to represent the probability of a particle being in an energy level with energy level $E$ divided by the probability of a particle having energy $\mu$, where $\mu$ is the zero-point energy (energy of a particle in its ground state). Since $\mu$ might not be zero, the Boltzmann factor should be $e^{-\beta (E - \mu) N}$ instead of $e^{-\beta E N}$, so the correct formula for $\overline{n}$ is
\[\overline{n} = \frac{g}{e^{(E - \mu) \beta} - 1} \]

\section{Freeze-out}
If temperature is very large, we can approximate average energy of a bunch of bosons by replacing the exponent function with its linear approximation. To make this look nicer, we'll suppose $\mu$ is zero and $g$ is one.
\[E_\text{avg} = E \cdot \overline{n} = \frac{E}{e^{E / k_B T} - 1} \approx \frac{E}{(1 + E / k_B T) - 1} = k_B T\]

If you suppose each boson contibutes one degree of freedom, this is equivalent to the equipartition theorem. However, if temperature is very small, $E_\text{avg}$ (the energy of each harmonic oscillator) will be significally smaller than what we'd expect from the approximation above. This is especially true when $E - \mu$ is large (relative to $T$), as is the case for oscillating solid atoms of Beryllium, Boron, Carbon, or Silicon. According to the equipartition theorem, we'd expect the specific heat capacity of crystals to be around $3 k_B T = 25 J / \text{mol} K$, but because of freeze-out, it's actually a bit less, and for the atoms listed above with unusually stiff bonds, it's significantly less. On the other hand, there are also solids with molar heat capacity above $3 k_B T$, but that's due to other effects.

\section{Fermi-Dirac distribution}
After some practice drawing those funky energy-level diagrams we did in class, we clearly see that energy levels far below the Fermi energy $E_F$ are very likely to be completely full, and energy levels far above $E_F$ are very likely to be completely empty. To derive that, we can just calculate the average occupancy of each energy level as
\[\overline{n}(E) = \frac{\sum\limits_{N=0}^1 N e^{- \beta E N}}{\sum\limits_{N=0}^1 e^{- \beta E N}}\]
That's the exact same fomula we used to derive the Bose-Einstein distribution, except the possible values for occupancy of each energy level are just 0 and 1, instead of all nonnegative integers. Simply plugging in the values to the summations turns that formula into
\[\overline{n} = \frac{e^{- \beta E}}{1 + e^{- \beta E}} = \frac{1}{1 + e^{\beta E}} \]
But once again, we have to modify that to account for degeneracy of energy levels. We also have to account for the zero-point energy, but since occupied states are unavailable, we use the Fermi energy ($E_F$) instead, which is the highest energy of the states occupied at absolute zero.

So the correct formula for the average occupancy of each energy level according to Fermi-Dirac statistics is
\[\overline{n}(E) = \frac{g}{e^{(E - E_F) \beta} + 1} \]

\end{document}
